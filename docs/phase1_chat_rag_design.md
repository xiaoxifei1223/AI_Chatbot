# Phase 1 èŠå¤©ä¸RAGæ··åˆç³»ç»Ÿè®¾è®¡
# Phase 1 Chat & RAG Hybrid System Design

---

## è®¾è®¡æ¦‚è¿° | Design Overview

**ä¸­æ–‡ï¼š**
Phase 1é‡‡ç”¨**LLM + RAGæ··åˆæ¶æ„**ï¼Œé€šè¿‡æ„å›¾åˆ†ç±»å™¨è‡ªåŠ¨è·¯ç”±ä¸åŒç±»å‹çš„é—®é¢˜ï¼š
- **é€šç”¨SREå’¨è¯¢** â†’ ç›´æ¥ä½¿ç”¨LLMï¼ˆå¿«é€Ÿå“åº”ï¼‰
- **ä»£ç å®¡æŸ¥è¯·æ±‚** â†’ Promptå·¥ç¨‹ + SREæ£€æŸ¥æ¸…å•
- **æ·±åº¦ä¸“ä¸šé—®é¢˜** â†’ RAGæ£€ç´¢ + LLMå¢å¼ºï¼ˆé«˜å‡†ç¡®æ€§ï¼‰

**English:**
Phase 1 adopts **LLM + RAG hybrid architecture**, automatically routing different question types via intent classifier:
- **General SRE consultation** â†’ Direct LLM (fast response)
- **Code review requests** â†’ Prompt engineering + SRE checklist
- **Deep professional questions** â†’ RAG retrieval + LLM enhancement (high accuracy)

---

## ç³»ç»Ÿæ¶æ„ | System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     å‰ç«¯ç”¨æˆ·è¾“å…¥                              â”‚
â”‚                  Frontend User Input                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  POST /api/v1/chat                           â”‚
â”‚                   (ç»Ÿä¸€èŠå¤©æ¥å£)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   IntentClassifier     â”‚
            â”‚    (æ„å›¾åˆ†ç±»å™¨)         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GENERAL_CHAT â”‚  â”‚ CODE_REVIEW  â”‚  â”‚ SPECIFIC_TECHâ”‚
â”‚  é€šç”¨å¯¹è¯     â”‚  â”‚  ä»£ç æ£€æŸ¥     â”‚  â”‚  æ·±åº¦é—®é¢˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚
       â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLMService   â”‚  â”‚ SREService   â”‚  â”‚ RAGService   â”‚
â”‚ (çº¯LLM)      â”‚  â”‚(Promptå·¥ç¨‹)  â”‚  â”‚(æ£€ç´¢å¢å¼º)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  ä¿å­˜èŠå¤©è®°å½•  â”‚
                 â”‚  è¿”å›å“åº”      â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ„å›¾åˆ†ç±»å™¨è®¾è®¡ | Intent Classifier Design

### é—®é¢˜ç±»å‹å®šä¹‰ | Question Type Definition

```python
# app/services/intent_classifier.py
from typing import Literal
from enum import Enum

class QuestionType(str, Enum):
    """é—®é¢˜ç±»å‹æšä¸¾"""
    GENERAL_CHAT = "general_chat"           # é€šç”¨å¯¹è¯
    CODE_REVIEW = "code_review"             # ä»£ç æ£€æŸ¥
    SRE_CONCEPT = "sre_concept"             # SREæ¦‚å¿µé—®é¢˜
    SPECIFIC_TECH = "specific_tech"         # å…·ä½“æŠ€æœ¯é—®é¢˜ï¼ˆéœ€è¦RAGï¼‰
```

---

### åˆ†ç±»å™¨å®ç° | Classifier Implementation

**æ–‡ä»¶è·¯å¾„ | File Path**: `app/services/intent_classifier.py`

```python
from typing import Literal
from enum import Enum

class QuestionType(str, Enum):
    GENERAL_CHAT = "general_chat"
    CODE_REVIEW = "code_review"
    SRE_CONCEPT = "sre_concept"
    SPECIFIC_TECH = "specific_tech"

class IntentClassifier:
    """
    é—®é¢˜æ„å›¾åˆ†ç±»å™¨
    Phase 1: åŸºäºè§„åˆ™çš„è½»é‡çº§å®ç°
    Phase 2: å¯å‡çº§ä¸ºå°å‹BERTåˆ†ç±»æ¨¡å‹
    """
    
    def __init__(self):
        # ä»£ç å—æ£€æµ‹æ¨¡å¼
        self.code_patterns = [
            "```",              # Markdownä»£ç å—
            "def ",             # Pythonå‡½æ•°
            "function ",        # JavaScriptå‡½æ•°
            "class ",           # ç±»å®šä¹‰
            "import ",          # å¯¼å…¥è¯­å¥
            "æ£€æŸ¥ä»£ç ",
            "review code",
            "çœ‹çœ‹è¿™æ®µ",
            "å¸®æˆ‘å®¡æŸ¥"
        ]
        
        # éœ€è¦RAGçš„æ·±åº¦é—®é¢˜å…³é”®è¯
        self.rag_keywords = [
            "æœ€ä½³å®è·µ",
            "best practice",
            "å…·ä½“æ¡ˆä¾‹",
            "è¯¦ç»†æ­¥éª¤",
            "å®Œæ•´æ–¹æ¡ˆ",
            "å®˜æ–¹æ–‡æ¡£",
            "æƒå¨",
            "æ ‡å‡†",
            "è§„èŒƒ",
            "å¦‚ä½•å®ç°",
            "ç”Ÿäº§ç¯å¢ƒ",
            "çœŸå®æ¡ˆä¾‹"
        ]
        
        # SREæ ¸å¿ƒæ¦‚å¿µ
        self.sre_concepts = [
            "SLO", "SLI", "SLA",
            "error budget", "é”™è¯¯é¢„ç®—",
            "å¯ç”¨æ€§", "availability",
            "å¯é æ€§", "reliability",
            "ç›‘æ§", "monitoring",
            "å‘Šè­¦", "alerting",
            "å››å¤§é»„é‡‘æŒ‡æ ‡",
            "golden signals",
            "ç†”æ–­", "circuit breaker",
            "é™çº§", "degradation",
            "é™æµ", "rate limiting"
        ]
    
    async def classify(self, message: str) -> QuestionType:
        """
        åˆ†ç±»é—®é¢˜ç±»å‹
        
        Args:
            message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
            
        Returns:
            QuestionType: é—®é¢˜ç±»å‹
        """
        message_lower = message.lower()
        
        # ä¼˜å…ˆçº§1: æ£€æµ‹ä»£ç å—ï¼ˆæœ€æ˜ç¡®ï¼‰
        if self._contains_code(message):
            return QuestionType.CODE_REVIEW
        
        # ä¼˜å…ˆçº§2: æ£€æµ‹éœ€è¦RAGçš„æ·±åº¦é—®é¢˜
        if self._needs_rag(message_lower):
            return QuestionType.SPECIFIC_TECH
        
        # ä¼˜å…ˆçº§3: æ£€æµ‹SREæ¦‚å¿µé—®é¢˜ï¼ˆå¯ä»¥ç”¨çº¯LLMï¼‰
        if self._is_sre_concept(message_lower):
            return QuestionType.SRE_CONCEPT
        
        # ä¼˜å…ˆçº§4: é»˜è®¤é€šç”¨å¯¹è¯
        return QuestionType.GENERAL_CHAT
    
    def _contains_code(self, message: str) -> bool:
        """æ£€æµ‹æ˜¯å¦åŒ…å«ä»£ç """
        return any(pattern in message for pattern in self.code_patterns)
    
    def _needs_rag(self, message_lower: str) -> bool:
        """æ£€æµ‹æ˜¯å¦éœ€è¦RAGå¢å¼º"""
        return any(keyword in message_lower for keyword in self.rag_keywords)
    
    def _is_sre_concept(self, message_lower: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºSREæ¦‚å¿µé—®é¢˜"""
        return any(concept.lower() in message_lower for concept in self.sre_concepts)
    
    async def should_use_rag(self, question_type: QuestionType) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨RAG
        
        Args:
            question_type: é—®é¢˜ç±»å‹
            
        Returns:
            bool: æ˜¯å¦ä½¿ç”¨RAG
        """
        return question_type in [
            QuestionType.SPECIFIC_TECH,
            # QuestionType.CODE_REVIEW  # Phase 1ä»£ç æ£€æŸ¥æš‚æ—¶ç”¨Promptå·¥ç¨‹
        ]
```

---

## ç»Ÿä¸€èŠå¤©æ¥å£ | Unified Chat API

**æ–‡ä»¶è·¯å¾„ | File Path**: `app/api/v1/chat.py`

```python
from fastapi import APIRouter, Depends
from sqlalchemy.ext.asyncio import AsyncSession
import time

from app.schemas.chat import ChatRequest, ChatResponse
from app.services.llm_service import LLMService
from app.services.rag_service import RAGService
from app.services.sre_service import SREService
from app.services.intent_classifier import IntentClassifier, QuestionType
from app.api.deps import get_db

router = APIRouter()

@router.post("/chat", response_model=ChatResponse)
async def chat(
    request: ChatRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    æ™ºèƒ½èŠå¤©æ¥å£ - è‡ªåŠ¨è·¯ç”±åˆ°åˆé€‚çš„å¤„ç†æ–¹å¼
    
    å·¥ä½œæµç¨‹ï¼š
    1. æ„å›¾åˆ†ç±»
    2. æ ¹æ®ç±»å‹é€‰æ‹©å¤„ç†æœåŠ¡ï¼ˆLLM/RAG/SREï¼‰
    3. ç”Ÿæˆå›ç­”
    4. ä¿å­˜èŠå¤©è®°å½•
    5. è¿”å›å“åº”
    """
    
    # æ­¥éª¤1: åˆ†ç±»é—®é¢˜ç±»å‹
    classifier = IntentClassifier()
    question_type = await classifier.classify(request.message)
    
    # æ­¥éª¤2: æ ¹æ®ç±»å‹è·¯ç”±åˆ°å¯¹åº”æœåŠ¡
    response_text = ""
    sre_analysis = None
    
    if question_type == QuestionType.CODE_REVIEW:
        # ä»£ç æ£€æŸ¥ - ä½¿ç”¨SREService
        sre_service = SREService(db)
        
        # æå–ä»£ç ç‰‡æ®µï¼ˆç®€åŒ–å¤„ç†ï¼‰
        code = request.message
        language = _detect_language(code)
        
        # æ‰§è¡ŒSREæ£€æŸ¥
        sre_analysis = await sre_service.check_code(
            code=code,
            language=language
        )
        
        # æ ¼å¼åŒ–æ£€æŸ¥ç»“æœä¸ºæ–‡æœ¬
        response_text = _format_sre_result(sre_analysis)
        
    elif await classifier.should_use_rag(question_type):
        # æ·±åº¦ä¸“ä¸šé—®é¢˜ - ä½¿ç”¨RAGå¢å¼º
        rag_service = RAGService(db)
        response_text = await rag_service.get_rag_enhanced_response(
            message=request.message,
            context=request.context
        )
        
    else:
        # é€šç”¨é—®é¢˜æˆ–SREæ¦‚å¿µ - ç›´æ¥ä½¿ç”¨LLM
        llm_service = LLMService(db)
        response_text = await llm_service.get_response(
            message=request.message,
            context=request.context
        )
    
    # æ­¥éª¤3: ä¿å­˜èŠå¤©è®°å½•
    llm_service = LLMService(db)
    
    # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    await llm_service.save_message(
        session_id=request.session_id,
        visitor_id=request.visitor_id,
        role="user",
        content=request.message
    )
    
    # ä¿å­˜AIå›å¤
    await llm_service.save_message(
        session_id=request.session_id,
        visitor_id=request.visitor_id,
        role="assistant",
        content=response_text
    )
    
    # æ­¥éª¤4: è¿”å›å“åº”
    return ChatResponse(
        success=True,
        data={
            "message": response_text,
            "session_id": request.session_id,
            "question_type": question_type,  # è¿”å›é—®é¢˜ç±»å‹ä¾›å‰ç«¯å‚è€ƒ
            "sre_analysis": sre_analysis,    # å¦‚æœæ˜¯ä»£ç æ£€æŸ¥ï¼Œè¿”å›ç»“æ„åŒ–ç»“æœ
            "timestamp": int(time.time() * 1000)
        }
    )


def _detect_language(code: str) -> str:
    """ç®€å•çš„ç¼–ç¨‹è¯­è¨€æ£€æµ‹"""
    if "def " in code or "import " in code:
        return "python"
    elif "function " in code or "const " in code:
        return "javascript"
    elif "public class" in code or "private " in code:
        return "java"
    else:
        return "unknown"


def _format_sre_result(analysis: dict) -> str:
    """æ ¼å¼åŒ–SREæ£€æŸ¥ç»“æœä¸ºå‹å¥½çš„æ–‡æœ¬"""
    result = "## ğŸ” SREä»£ç æ£€æŸ¥ç»“æœ\n\n"
    
    # æ€»ä½“è¯„åˆ†
    score = analysis.get("overall_score", 0)
    result += f"**æ€»ä½“è¯„åˆ†**: {score}/100\n\n"
    
    # æ£€æŸ¥é¡¹
    check_items = analysis.get("check_items", [])
    if check_items:
        result += "### æ£€æŸ¥é¡¹è¯¦æƒ…\n\n"
        for item in check_items:
            status_icon = "âœ…" if item["status"] == "pass" else "âš ï¸" if item["status"] == "warning" else "âŒ"
            result += f"{status_icon} **{item['category']}**: {item['message']}\n"
        result += "\n"
    
    # æ”¹è¿›å»ºè®®
    suggestions = analysis.get("suggestions", [])
    if suggestions:
        result += "### ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
        for i, sug in enumerate(suggestions, 1):
            priority_icon = "ğŸ”´" if sug["priority"] == "high" else "ğŸŸ¡" if sug["priority"] == "medium" else "ğŸŸ¢"
            result += f"{i}. {priority_icon} {sug['text']}\n"
    
    return result
```

---

## RAGæœåŠ¡å®ç° | RAG Service Implementation

**æ–‡ä»¶è·¯å¾„ | File Path**: `app/services/rag_service.py`

```python
from typing import List, Dict, Optional
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import settings

class RAGService:
    """
    RAGæœåŠ¡ - æ£€ç´¢å¢å¼ºç”Ÿæˆ
    Phase 1: ä½¿ç”¨æœ¬åœ°Chromaå‘é‡æ•°æ®åº“
    """
    
    def __init__(self, db: AsyncSession):
        self.db = db
        
        # åˆå§‹åŒ–Embeddingæ¨¡å‹
        self.embeddings = OpenAIEmbeddings(
            api_key=settings.OPENAI_API_KEY
        )
        
        # åˆå§‹åŒ–æœ¬åœ°å‘é‡æ•°æ®åº“
        self.vectorstore = Chroma(
            persist_directory="./data/chroma_db",
            embedding_function=self.embeddings,
            collection_name="sre_knowledge"
        )
        
        # åˆå§‹åŒ–LLM
        self.llm = ChatOpenAI(
            api_key=settings.OPENAI_API_KEY,
            model=settings.LLM_MODEL,
            temperature=0.3  # è¾ƒä½æ¸©åº¦ä¿è¯å‡†ç¡®æ€§
        )
    
    async def get_rag_enhanced_response(
        self,
        message: str,
        context: Optional[List[Dict]] = None
    ) -> str:
        """
        ä½¿ç”¨RAGå¢å¼ºçš„å›ç­”
        
        Args:
            message: ç”¨æˆ·é—®é¢˜
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæš‚æ—¶ä¸ç”¨äºRAGï¼‰
            
        Returns:
            str: å¢å¼ºåçš„å›ç­”
        """
        # 1. é…ç½®æ£€ç´¢å™¨
        retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={
                "k": 3  # è¿”å›æœ€ç›¸å…³çš„3ä¸ªæ–‡æ¡£ç‰‡æ®µ
            }
        )
        
        # 2. æ„å»ºRetrievalQAé“¾
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",  # Phase 1ä½¿ç”¨ç®€å•çš„stuffæ–¹å¼
            retriever=retriever,
            return_source_documents=True,  # è¿”å›æ¥æºæ–‡æ¡£
            chain_type_kwargs={
                "prompt": self._get_qa_prompt()
            }
        )
        
        # 3. æ‰§è¡ŒæŸ¥è¯¢
        result = await qa_chain.ainvoke({"query": message})
        
        # 4. æ ¼å¼åŒ–å›ç­”ï¼ˆåŒ…å«æ¥æºï¼‰
        answer = result["result"]
        sources = result.get("source_documents", [])
        
        # 5. æ·»åŠ æ¥æºå¼•ç”¨
        if sources:
            answer += "\n\n---\nğŸ“š **å‚è€ƒæ¥æº**ï¼š\n"
            for i, doc in enumerate(sources[:2], 1):  # åªæ˜¾ç¤ºå‰2ä¸ªæ¥æº
                source = doc.metadata.get("source", "SREå†…éƒ¨çŸ¥è¯†åº“")
                snippet = doc.page_content[:100] + "..."
                answer += f"\n{i}. {source}\n   > {snippet}\n"
        
        return answer
    
    def _get_qa_prompt(self):
        """è·å–QA Promptæ¨¡æ¿"""
        from langchain.prompts import PromptTemplate
        
        template = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„SREä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹å‚è€ƒæ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

å‚è€ƒæ–‡æ¡£ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š
{question}

å›ç­”è¦æ±‚ï¼š
1. åŸºäºå‚è€ƒæ–‡æ¡£æä¾›å‡†ç¡®ã€ä¸“ä¸šçš„å»ºè®®
2. å¦‚æœå‚è€ƒæ–‡æ¡£ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. æä¾›å…·ä½“çš„å®æ–½æ­¥éª¤æˆ–ä»£ç ç¤ºä¾‹
4. çªå‡ºSREæœ€ä½³å®è·µ

å›ç­”ï¼š
"""
        return PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )
    
    async def initialize_knowledge_base(self, documents: List[str]):
        """
        åˆå§‹åŒ–çŸ¥è¯†åº“ï¼ˆä¸€æ¬¡æ€§æ“ä½œï¼‰
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
        """
        # 1. æ–‡æ¡£åˆ†å—
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", " ", ""]
        )
        
        splits = text_splitter.create_documents(documents)
        
        # 2. æ·»åŠ å…ƒæ•°æ®
        for i, split in enumerate(splits):
            split.metadata = {
                "source": f"SREæœ€ä½³å®è·µæ–‡æ¡£ {i+1}",
                "doc_id": i
            }
        
        # 3. å­˜å…¥å‘é‡æ•°æ®åº“
        self.vectorstore = Chroma.from_documents(
            documents=splits,
            embedding=self.embeddings,
            persist_directory="./data/chroma_db",
            collection_name="sre_knowledge"
        )
        
        # 4. æŒä¹…åŒ–
        self.vectorstore.persist()
        
        print(f"âœ… å·²åŠ è½½ {len(splits)} ä¸ªæ–‡æ¡£ç‰‡æ®µåˆ°çŸ¥è¯†åº“")
    
    async def add_document(self, content: str, metadata: dict = None):
        """
        åŠ¨æ€æ·»åŠ å•ä¸ªæ–‡æ¡£åˆ°çŸ¥è¯†åº“
        
        Args:
            content: æ–‡æ¡£å†…å®¹
            metadata: æ–‡æ¡£å…ƒæ•°æ®
        """
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        
        splits = text_splitter.create_documents([content])
        
        # æ·»åŠ å…ƒæ•°æ®
        for split in splits:
            split.metadata = metadata or {"source": "åŠ¨æ€æ·»åŠ "}
        
        # æ·»åŠ åˆ°å‘é‡åº“
        self.vectorstore.add_documents(splits)
        self.vectorstore.persist()
```

---

## SREçŸ¥è¯†åº“åˆå§‹åŒ– | SRE Knowledge Base Initialization

**æ–‡ä»¶è·¯å¾„ | File Path**: `scripts/init_knowledge_base.py`

```python
"""
åˆå§‹åŒ–SREçŸ¥è¯†åº“è„šæœ¬
Phase 1: æ‰‹åŠ¨ç»´æŠ¤çš„æ ¸å¿ƒSREæœ€ä½³å®è·µæ–‡æ¡£
"""

SRE_KNOWLEDGE_DOCS = [
    # æ–‡æ¡£1: SREå››å¤§é»„é‡‘æŒ‡æ ‡
    """
# SREå››å¤§é»„é‡‘æŒ‡æ ‡ (The Four Golden Signals)

SREçš„ç›‘æ§æ ¸å¿ƒå›´ç»•å››ä¸ªå…³é”®æŒ‡æ ‡å±•å¼€ï¼š

## 1. å»¶è¿Ÿ (Latency)
**å®šä¹‰**: æœåŠ¡å¤„ç†è¯·æ±‚æ‰€éœ€çš„æ—¶é—´

**ç›‘æ§å»ºè®®**:
- ä½¿ç”¨åˆ†ä½æ•°ç»Ÿè®¡ï¼šP50ã€P95ã€P99
- åŒºåˆ†æˆåŠŸè¯·æ±‚å’Œå¤±è´¥è¯·æ±‚çš„å»¶è¿Ÿ
- å»ºè®®å‘Šè­¦é˜ˆå€¼ï¼šP95 > 200msï¼ŒP99 > 500ms

**ä»£ç ç¤ºä¾‹** (Python):
```python
import time
from prometheus_client import Histogram

request_latency = Histogram(
    'http_request_duration_seconds',
    'HTTP request latency',
    ['method', 'endpoint']
)

@request_latency.time()
def handle_request():
    # å¤„ç†è¯·æ±‚
    pass
```

## 2. æµé‡ (Traffic)
**å®šä¹‰**: ç³»ç»Ÿæ¯ç§’å¤„ç†çš„è¯·æ±‚æ•°é‡

**ç›‘æ§æŒ‡æ ‡**:
- QPS (Queries Per Second)
- RPS (Requests Per Second)
- ååé‡ (Throughput)

**å®¹é‡è§„åˆ’**:
- å»ºç«‹åŸºçº¿ï¼šæ­£å¸¸æµé‡èŒƒå›´
- å³°å€¼æµé‡è¯†åˆ«
- è®¾ç½®æ‰©å®¹é˜ˆå€¼

## 3. é”™è¯¯ (Errors)
**å®šä¹‰**: è¯·æ±‚å¤±è´¥çš„æ¯”ç‡

**ç›‘æ§ç»´åº¦**:
- HTTP 4xx: å®¢æˆ·ç«¯é”™è¯¯
- HTTP 5xx: æœåŠ¡ç«¯é”™è¯¯
- ä¸šåŠ¡é”™è¯¯ç‡

**SLOå»ºè®®**:
- ç›®æ ‡ï¼šé”™è¯¯ç‡ < 0.1% (å³99.9%æˆåŠŸç‡)
- å…³é”®æ¥å£ï¼šé”™è¯¯ç‡ < 0.01% (99.99%æˆåŠŸç‡)

## 4. é¥±å’Œåº¦ (Saturation)
**å®šä¹‰**: ç³»ç»Ÿèµ„æºçš„åˆ©ç”¨ç‡

**ç›‘æ§èµ„æº**:
- CPUä½¿ç”¨ç‡
- å†…å­˜ä½¿ç”¨ç‡
- ç£ç›˜IO
- ç½‘ç»œå¸¦å®½

**å‘Šè­¦é˜ˆå€¼**:
- é€šç”¨æœåŠ¡ï¼š80%å‘Šè­¦ï¼Œ90%ç´§æ€¥
- æ•°æ®åº“ï¼š70%å‘Šè­¦ï¼Œ85%ç´§æ€¥
""",

    # æ–‡æ¡£2: é”™è¯¯é¢„ç®—
    """
# é”™è¯¯é¢„ç®— (Error Budget)

## æ¦‚å¿µ
é”™è¯¯é¢„ç®—æ˜¯SREä¸­å¹³è¡¡å¯é æ€§ä¸å¿«é€Ÿè¿­ä»£çš„æ ¸å¿ƒå·¥å…·ã€‚

**å®šä¹‰**: åœ¨æ»¡è¶³SLOçš„å‰æä¸‹ï¼Œå…è®¸çš„æœ€å¤§é”™è¯¯é‡ã€‚

## è®¡ç®—æ–¹æ³•

### åŸºäºå¯ç”¨æ€§çš„é”™è¯¯é¢„ç®—
å‡è®¾SLO = 99.9% (ä¸‰ä¸ªä¹)

**æœˆåº¦é”™è¯¯é¢„ç®—**:
- ä¸€ä¸ªæœˆ = 30å¤© = 43200åˆ†é’Ÿ
- é”™è¯¯é¢„ç®— = 43200 Ã— (1 - 0.999) = 43.2åˆ†é’Ÿ
- å³ï¼šæ¯æœˆå¯ä»¥åœæœº43.2åˆ†é’Ÿ

**å­£åº¦é”™è¯¯é¢„ç®—**:
- ä¸€ä¸ªå­£åº¦ = 90å¤©
- é”™è¯¯é¢„ç®— = 129.6åˆ†é’Ÿ â‰ˆ 2.16å°æ—¶

### åŸºäºè¯·æ±‚çš„é”™è¯¯é¢„ç®—
å‡è®¾æœˆåº¦100ä¸‡æ¬¡è¯·æ±‚ï¼ŒSLO = 99.9%

**é”™è¯¯é¢„ç®—**:
- å…è®¸å¤±è´¥è¯·æ±‚ = 1,000,000 Ã— 0.001 = 1,000æ¬¡
- æ¯å¤©é¢„ç®— â‰ˆ 33æ¬¡å¤±è´¥è¯·æ±‚

## ä½¿ç”¨åœºæ™¯

### 1. å‘å¸ƒå†³ç­–
```
if é”™è¯¯é¢„ç®—å……è¶³ (>50%):
    âœ… å¯ä»¥åŠ å¿«åŠŸèƒ½å‘å¸ƒ
    âœ… å¯ä»¥è¿›è¡Œå®éªŒæ€§å˜æ›´
else if é”™è¯¯é¢„ç®—ç´§å¼  (20%-50%):
    âš ï¸ è°¨æ…å‘å¸ƒï¼Œå¢åŠ æµ‹è¯•
    âš ï¸ é¿å…é£é™©å˜æ›´
else:  # é”™è¯¯é¢„ç®—è€—å°½ (<20%)
    âŒ å†»ç»“åŠŸèƒ½å‘å¸ƒ
    âŒ ä¸“æ³¨ç¨³å®šæ€§æ”¹è¿›
    âŒ ä¿®å¤å·²çŸ¥é—®é¢˜
```

### 2. å›¢é˜Ÿæ¿€åŠ±
- é”™è¯¯é¢„ç®—æ˜¯å®¢è§‚æŒ‡æ ‡ï¼Œé¿å…ä¸»è§‚åˆ¤æ–­
- SREå›¢é˜Ÿå’Œå¼€å‘å›¢é˜Ÿå…±åŒå¯¹é”™è¯¯é¢„ç®—è´Ÿè´£
- é¢„ç®—å……è¶³æ—¶é¼“åŠ±åˆ›æ–°ï¼Œé¢„ç®—ç´§å¼ æ—¶ä¸“æ³¨è´¨é‡

## ç›‘æ§å»ºè®®
```python
# å®æ—¶è¿½è¸ªé”™è¯¯é¢„ç®—æ¶ˆè€—
def calculate_error_budget_burn_rate():
    current_error_rate = get_current_error_rate()
    slo_target = 0.999
    
    burn_rate = current_error_rate / (1 - slo_target)
    
    if burn_rate > 10:
        alert("é”™è¯¯é¢„ç®—æ¶ˆè€—è¿‡å¿«ï¼")
    elif burn_rate > 5:
        warning("é”™è¯¯é¢„ç®—æ¶ˆè€—åé«˜")
    
    return burn_rate
```

## æœ€ä½³å®è·µ
1. **å¯è§†åŒ–**: å®æ—¶Dashboardæ˜¾ç¤ºå‰©ä½™é¢„ç®—
2. **è‡ªåŠ¨åŒ–**: é¢„ç®—å‘Šè­¦è‡ªåŠ¨è§¦å‘
3. **é€æ˜åŒ–**: å…¨å›¢é˜Ÿå¯è§é”™è¯¯é¢„ç®—çŠ¶æ€
4. **å®šæœŸReview**: æ¯å‘¨/æœˆå›é¡¾é¢„ç®—ä½¿ç”¨æƒ…å†µ
""",

    # æ–‡æ¡£3: ä»£ç å®¡æŸ¥SREæ£€æŸ¥æ¸…å•
    """
# ä»£ç å®¡æŸ¥SREæ£€æŸ¥æ¸…å•
# SRE Code Review Checklist

åœ¨è¿›è¡Œä»£ç å®¡æŸ¥æ—¶ï¼Œä»SREè§’åº¦éœ€è¦å…³æ³¨ä»¥ä¸‹ç»´åº¦ï¼š

## âœ… 1. å¯é æ€§ (Reliability)

### å¼‚å¸¸å¤„ç†
- [ ] **æ˜¯å¦æœ‰å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Ÿ**
  ```python
  # âŒ é”™è¯¯ç¤ºä¾‹
  def get_user(user_id):
      user = db.query(f"SELECT * FROM users WHERE id={user_id}")
      return user
  
  # âœ… æ­£ç¡®ç¤ºä¾‹
  def get_user(user_id):
      try:
          user = db.query("SELECT * FROM users WHERE id=?", (user_id,))
          return user
      except DatabaseError as e:
          logger.error(f"Failed to get user {user_id}: {e}")
          raise ServiceUnavailableError("Database temporarily unavailable")
  ```

### è¶…æ—¶è®¾ç½®
- [ ] **æ•°æ®åº“æ“ä½œæ˜¯å¦æœ‰è¶…æ—¶ï¼Ÿ**
  ```python
  # âœ… è®¾ç½®è¶…æ—¶
  db.execute(query, timeout=5)  # 5ç§’è¶…æ—¶
  ```

### é‡è¯•æœºåˆ¶
- [ ] **æ˜¯å¦æœ‰é‡è¯•æœºåˆ¶ï¼ˆå¹‚ç­‰æ“ä½œï¼‰ï¼Ÿ**
  ```python
  from tenacity import retry, stop_after_attempt, wait_exponential
  
  @retry(
      stop=stop_after_attempt(3),
      wait=wait_exponential(multiplier=1, min=1, max=10)
  )
  def call_external_api():
      response = requests.get(api_url, timeout=5)
      response.raise_for_status()
      return response.json()
  ```

### ç†”æ–­å™¨
- [ ] **å…³é”®æœåŠ¡æ˜¯å¦æœ‰ç†”æ–­ä¿æŠ¤ï¼Ÿ**
  ```python
  from pybreaker import CircuitBreaker
  
  breaker = CircuitBreaker(fail_max=5, timeout_duration=60)
  
  @breaker
  def call_payment_service():
      return payment_api.charge(...)
  ```

## âœ… 2. å¯è§‚æµ‹æ€§ (Observability)

### æ—¥å¿—è®°å½•
- [ ] **å…³é”®è·¯å¾„æ˜¯å¦æœ‰æ—¥å¿—ï¼Ÿ**
- [ ] **æ—¥å¿—çº§åˆ«æ˜¯å¦åˆç†ï¼Ÿ**
  ```python
  # âœ… åˆç†çš„æ—¥å¿—
  logger.info(f"User {user_id} login successful")  # æ­£å¸¸æµç¨‹
  logger.warning(f"Retry attempt {retry_count}")   # å¼‚å¸¸ä½†å¯æ¢å¤
  logger.error(f"Payment failed: {error}")         # é”™è¯¯éœ€è¦å…³æ³¨
  ```

- [ ] **é¿å…è¿‡å¤šDEBUGæ—¥å¿—å½±å“æ€§èƒ½**

### æŒ‡æ ‡åŸ‹ç‚¹
- [ ] **æ˜¯å¦æœ‰æ€§èƒ½æŒ‡æ ‡ï¼Ÿ**
  ```python
  from prometheus_client import Counter, Histogram
  
  request_count = Counter('api_requests_total', 'Total API requests')
  request_duration = Histogram('api_request_duration_seconds', 'API request duration')
  
  @request_duration.time()
  def handle_api():
      request_count.inc()
      # å¤„ç†é€»è¾‘
  ```

### é“¾è·¯è¿½è¸ª
- [ ] **åˆ†å¸ƒå¼è°ƒç”¨æ˜¯å¦æœ‰trace_idï¼Ÿ**

## âœ… 3. æ€§èƒ½ (Performance)

### æ•°æ®åº“ä¼˜åŒ–
- [ ] **æŸ¥è¯¢æ˜¯å¦æœ‰ç´¢å¼•ï¼Ÿ**
- [ ] **æ˜¯å¦é¿å…N+1æŸ¥è¯¢ï¼Ÿ**
  ```python
  # âŒ N+1æŸ¥è¯¢
  users = User.query.all()
  for user in users:
      user.profile  # æ¯æ¬¡è§¦å‘å•ç‹¬æŸ¥è¯¢
  
  # âœ… ä½¿ç”¨JOINæˆ–é¢„åŠ è½½
  users = User.query.options(joinedload(User.profile)).all()
  ```

### ç¼“å­˜ç­–ç•¥
- [ ] **çƒ­ç‚¹æ•°æ®æ˜¯å¦ç¼“å­˜ï¼Ÿ**
  ```python
  from functools import lru_cache
  
  @lru_cache(maxsize=1000)
  def get_config(key):
      return db.get_config(key)
  ```

### åˆ†é¡µ
- [ ] **å¤§æ•°æ®é›†æ˜¯å¦åˆ†é¡µï¼Ÿ**

## âœ… 4. å®‰å…¨æ€§ (Security)

### è¾“å…¥éªŒè¯
- [ ] **ç”¨æˆ·è¾“å…¥æ˜¯å¦éªŒè¯ï¼Ÿ**
  ```python
  from pydantic import BaseModel, validator
  
  class UserInput(BaseModel):
      email: str
      
      @validator('email')
      def validate_email(cls, v):
          if '@' not in v:
              raise ValueError('Invalid email')
          return v
  ```

### SQLæ³¨å…¥é˜²æŠ¤
- [ ] **SQLæ˜¯å¦å‚æ•°åŒ–ï¼Ÿ**
  ```python
  # âŒ SQLæ³¨å…¥é£é™©
  query = f"SELECT * FROM users WHERE name='{user_input}'"
  
  # âœ… å‚æ•°åŒ–æŸ¥è¯¢
  query = "SELECT * FROM users WHERE name=?"
  db.execute(query, (user_input,))
  ```

### æ•æ„Ÿä¿¡æ¯
- [ ] **å¯†ç ã€å¯†é’¥æ˜¯å¦åŠ å¯†å­˜å‚¨ï¼Ÿ**
- [ ] **æ—¥å¿—æ˜¯å¦åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Ÿ**

## âœ… 5. å¯ç”¨æ€§ (Availability)

### é™çº§ç­–ç•¥
- [ ] **å…³é”®åŠŸèƒ½å¤±è´¥æ—¶æ˜¯å¦æœ‰é™çº§æ–¹æ¡ˆï¼Ÿ**
  ```python
  def get_recommendations(user_id):
      try:
          return recommendation_service.get(user_id)
      except ServiceError:
          # é™çº§ï¼šè¿”å›çƒ­é—¨æ¨è
          return get_popular_items()
  ```

### å¥åº·æ£€æŸ¥
- [ ] **æ˜¯å¦æä¾›å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼Ÿ**
  ```python
  @app.get("/health")
  async def health_check():
      # æ£€æŸ¥æ•°æ®åº“è¿æ¥
      db_ok = await check_database()
      # æ£€æŸ¥ç¼“å­˜
      cache_ok = await check_cache()
      
      if db_ok and cache_ok:
          return {"status": "healthy"}
      else:
          return {"status": "unhealthy"}, 503
  ```
""",

    # æ–‡æ¡£4: SLO/SLI/SLAå®šä¹‰
    """
# SLOã€SLIã€SLAè¯¦è§£

## æ ¸å¿ƒæ¦‚å¿µ

### SLI (Service Level Indicator) - æœåŠ¡ç­‰çº§æŒ‡æ ‡
**å®šä¹‰**: è¡¡é‡æœåŠ¡è´¨é‡çš„å…·ä½“æŒ‡æ ‡

**å¸¸è§SLI**:
- **å¯ç”¨æ€§**: æˆåŠŸè¯·æ±‚ / æ€»è¯·æ±‚
- **å»¶è¿Ÿ**: P95å“åº”æ—¶é—´ < 200ms
- **ååé‡**: QPS > 1000
- **æ­£ç¡®æ€§**: æ•°æ®ä¸€è‡´æ€§ > 99.99%

**ç¤ºä¾‹**:
```
SLI: è¿‡å»30å¤©å†…ï¼Œ95%çš„HTTPè¯·æ±‚åœ¨200mså†…è¿”å›
è®¡ç®—: P95å»¶è¿Ÿ = 180ms âœ… (æ»¡è¶³)
```

### SLO (Service Level Objective) - æœåŠ¡ç­‰çº§ç›®æ ‡
**å®šä¹‰**: å¯¹SLIè®¾å®šçš„ç›®æ ‡å€¼

**ç¤ºä¾‹**:
```
SLO: APIå¯ç”¨æ€§ â‰¥ 99.9%
SLO: P95å»¶è¿Ÿ â‰¤ 200ms
SLO: é”™è¯¯ç‡ â‰¤ 0.1%
```

**è®¾å®šåŸåˆ™**:
1. ä¸è¦è®¾ç½®100%ï¼ˆä¸ç°å®ï¼‰
2. åŸºäºç”¨æˆ·ä½“éªŒè®¾å®šï¼ˆç”¨æˆ·èƒ½æ„ŸçŸ¥çš„é˜ˆå€¼ï¼‰
3. ç•™æœ‰æ”¹è¿›ç©ºé—´

### SLA (Service Level Agreement) - æœåŠ¡ç­‰çº§åè®®
**å®šä¹‰**: ä¸å®¢æˆ·çš„æ­£å¼æ‰¿è¯ºï¼Œè¿åæœ‰èµ”å¿

**ç¤ºä¾‹**:
```
SLA: æœˆåº¦å¯ç”¨æ€§ â‰¥ 99.95%
å¦‚æœä½äº99.95%: é€€æ¬¾10%
å¦‚æœä½äº99.9%: é€€æ¬¾25%
```

## å…³ç³»
```
SLI (æµ‹é‡æŒ‡æ ‡)
  â†“
SLO (å†…éƒ¨ç›®æ ‡ï¼Œé€šå¸¸ä¸¥æ ¼äºSLA)
  â†“
SLA (å¯¹å¤–æ‰¿è¯ºï¼Œæ³•å¾‹çº¦æŸ)
```

## è®¾å®šç¤ºä¾‹

### Web APIæœåŠ¡
```yaml
SLI:
  - å¯ç”¨æ€§: æˆåŠŸå“åº”æ•° / æ€»è¯·æ±‚æ•°
  - å»¶è¿Ÿ: P95å“åº”æ—¶é—´
  - é”™è¯¯ç‡: 5xxé”™è¯¯æ•° / æ€»è¯·æ±‚æ•°

SLO:
  - å¯ç”¨æ€§ â‰¥ 99.9% (æœˆåº¦)
  - P95å»¶è¿Ÿ â‰¤ 200ms
  - é”™è¯¯ç‡ â‰¤ 0.1%

SLA:
  - å¯ç”¨æ€§ â‰¥ 99.5% (ä½äºSLOï¼Œç•™æœ‰buffer)
```

### æ•°æ®ç®¡é“
```yaml
SLI:
  - æ•°æ®æ–°é²œåº¦: æœ€æ–°æ•°æ®æ—¶é—´æˆ³è·ç¦»ç°åœ¨çš„æ—¶é—´
  - æ•°æ®å®Œæ•´æ€§: æˆåŠŸå¤„ç†è®°å½•æ•° / æ€»è®°å½•æ•°

SLO:
  - æ•°æ®å»¶è¿Ÿ â‰¤ 5åˆ†é’Ÿ
  - æ•°æ®å®Œæ•´æ€§ â‰¥ 99.99%

SLA:
  - æ•°æ®å»¶è¿Ÿ â‰¤ 15åˆ†é’Ÿ
```

## ç›‘æ§å®ç°
```python
from prometheus_client import Counter, Histogram, Gauge

# SLIæŒ‡æ ‡
request_total = Counter('http_requests_total', 'Total HTTP requests', ['status'])
request_duration = Histogram('http_request_duration_seconds', 'HTTP request latency')
error_rate = Gauge('http_error_rate', 'Current error rate')

def calculate_sli():
    # è®¡ç®—å¯ç”¨æ€§SLI
    total_requests = request_total._value.sum()
    success_requests = request_total.labels(status='2xx')._value.sum()
    availability_sli = success_requests / total_requests if total_requests > 0 else 1
    
    # è®¡ç®—å»¶è¿ŸSLI
    p95_latency = request_duration.observe(0.95)
    
    return {
        'availability': availability_sli,
        'latency_p95': p95_latency
    }
```
""",

    # æ–‡æ¡£5: å‘Šè­¦è®¾è®¡æœ€ä½³å®è·µ
    """
# å‘Šè­¦è®¾è®¡æœ€ä½³å®è·µ

## å‘Šè­¦åŸåˆ™

### 1. å‘Šè­¦å¿…é¡»å¯æ“ä½œ
**è§„åˆ™**: æ¯æ¡å‘Šè­¦å¿…é¡»æœ‰æ˜ç¡®çš„å¤„ç†æ­¥éª¤

âŒ **é”™è¯¯ç¤ºä¾‹**:
```
å‘Šè­¦: CPUä½¿ç”¨ç‡è¶…è¿‡80%
é—®é¢˜: ç„¶åå‘¢ï¼Ÿéœ€è¦åšä»€ä¹ˆï¼Ÿ
```

âœ… **æ­£ç¡®ç¤ºä¾‹**:
```
å‘Šè­¦: APIæœåŠ¡CPUä½¿ç”¨ç‡è¶…è¿‡80%
å¤„ç†æ­¥éª¤:
1. æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸æµé‡
2. æŸ¥çœ‹æ…¢æŸ¥è¯¢æ—¥å¿—
3. å¦‚æœæŒç»­5åˆ†é’Ÿï¼Œè§¦å‘è‡ªåŠ¨æ‰©å®¹
4. å¦‚æœæ— æ³•è‡ªåŠ¨æ¢å¤ï¼Œå‡çº§åˆ°on-callå·¥ç¨‹å¸ˆ
```

### 2. é¿å…å‘Šè­¦ç–²åŠ³
**è§„åˆ™**: å‡å°‘å™ªéŸ³ï¼Œåªå‘Šè­¦çœŸæ­£çš„é—®é¢˜

**ç­–ç•¥**:
- ä½¿ç”¨é˜ˆå€¼ç»„åˆï¼šCPU > 80% **ä¸”** æŒç»­5åˆ†é’Ÿ
- è®¾ç½®å‘Šè­¦é¢‘ç‡é™åˆ¶ï¼šåŒä¸€é—®é¢˜10åˆ†é’Ÿå†…åªå‘Šè­¦ä¸€æ¬¡
- åŒºåˆ†ä¸¥é‡çº§åˆ«ï¼šP0ç´§æ€¥ã€P1é‡è¦ã€P2ä¸€èˆ¬

### 3. åŸºäºç—‡çŠ¶è€ŒéåŸå› å‘Šè­¦
âœ… å‘Šè­¦: "APIå“åº”æ—¶é—´P95 > 500ms"ï¼ˆç”¨æˆ·èƒ½æ„ŸçŸ¥ï¼‰
âŒ å‘Šè­¦: "Redisè¿æ¥æ•° > 100"ï¼ˆæŠ€æœ¯æŒ‡æ ‡ï¼Œç”¨æˆ·ä¸ä¸€å®šå—å½±å“ï¼‰

## å‘Šè­¦çº§åˆ«

### P0 - ç´§æ€¥ (Critical)
**å®šä¹‰**: å½±å“æ ¸å¿ƒä¸šåŠ¡ï¼Œéœ€è¦ç«‹å³å“åº”

**è§¦å‘æ¡ä»¶**:
- æ ¸å¿ƒAPIå®Œå…¨ä¸å¯ç”¨
- æ•°æ®ä¸¢å¤±é£é™©
- å®‰å…¨æ¼æ´

**å“åº”æ—¶é—´**: 5åˆ†é’Ÿå†…
**é€šçŸ¥æ–¹å¼**: ç”µè¯ + çŸ­ä¿¡ + IM

### P1 - é‡è¦ (High)
**å®šä¹‰**: éƒ¨åˆ†åŠŸèƒ½ä¸å¯ç”¨æˆ–ä¸¥é‡é™çº§

**è§¦å‘æ¡ä»¶**:
- é”™è¯¯ç‡ > 1%
- P95å»¶è¿Ÿ > 1ç§’
- éƒ¨åˆ†åŒºåŸŸæœåŠ¡ä¸­æ–­

**å“åº”æ—¶é—´**: 30åˆ†é’Ÿå†…
**é€šçŸ¥æ–¹å¼**: çŸ­ä¿¡ + IM

### P2 - ä¸€èˆ¬ (Medium)
**å®šä¹‰**: æ€§èƒ½ä¸‹é™ï¼Œä½†åœ¨å¯æ¥å—èŒƒå›´

**è§¦å‘æ¡ä»¶**:
- é”™è¯¯ç‡ 0.5% - 1%
- P95å»¶è¿Ÿ 500ms - 1ç§’

**å“åº”æ—¶é—´**: å·¥ä½œæ—¶é—´å†…å¤„ç†
**é€šçŸ¥æ–¹å¼**: IM

### P3 - ä½ (Low)
**å®šä¹‰**: æ½œåœ¨é—®é¢˜ï¼Œä¸å½±å“ç”¨æˆ·

**è§¦å‘æ¡ä»¶**:
- ç£ç›˜ä½¿ç”¨ç‡ > 70%ï¼ˆè¿˜æœ‰ç¼“å†²ï¼‰
- ä¾èµ–æœåŠ¡å»¶è¿Ÿå‡é«˜

**å“åº”æ—¶é—´**: ä¸€å‘¨å†…å¤„ç†
**é€šçŸ¥æ–¹å¼**: å·¥å•

## å‘Šè­¦è§„åˆ™ç¤ºä¾‹

### é»„é‡‘æŒ‡æ ‡å‘Šè­¦
```yaml
# Prometheuså‘Šè­¦è§„åˆ™
groups:
  - name: golden_signals
    interval: 30s
    rules:
      # å»¶è¿Ÿå‘Šè­¦
      - alert: HighLatency
        expr: histogram_quantile(0.95, http_request_duration_seconds) > 0.5
        for: 5m
        labels:
          severity: P1
        annotations:
          summary: "APIå»¶è¿Ÿè¿‡é«˜"
          description: "{{ $labels.endpoint }} P95å»¶è¿Ÿ {{ $value }}ç§’"
      
      # é”™è¯¯ç‡å‘Šè­¦
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) 
          / 
          sum(rate(http_requests_total[5m])) > 0.01
        for: 5m
        labels:
          severity: P0
        annotations:
          summary: "é”™è¯¯ç‡è¶…è¿‡1%"
          
      # é¥±å’Œåº¦å‘Šè­¦
      - alert: HighCPU
        expr: cpu_usage > 0.8
        for: 10m
        labels:
          severity: P2
        annotations:
          summary: "CPUä½¿ç”¨ç‡æŒç»­é«˜äº80%"
```

## å‘Šè­¦é™å™ªæŠ€å·§

### 1. ä½¿ç”¨æ—¶é—´çª—å£
```
# é¿å…çŸ­æš‚æŠ–åŠ¨
for: 5m  # æŒç»­5åˆ†é’Ÿæ‰å‘Šè­¦
```

### 2. èšåˆå‘Šè­¦
```python
# å•ä¸ªå®ä¾‹æ•…éšœä¸å‘Šè­¦ï¼Œå¤šä¸ªå®ä¾‹æ•…éšœæ‰å‘Šè­¦
if failed_instances >= total_instances * 0.3:
    trigger_alert()
```

### 3. ä¾èµ–å‘Šè­¦æŠ‘åˆ¶
```
# å¦‚æœæ•°æ®åº“å·²ç»å‘Šè­¦ï¼ŒæŠ‘åˆ¶ä¾èµ–æ•°æ®åº“çš„æœåŠ¡å‘Šè­¦
if database_down:
    suppress(api_service_alerts)
```

### 4. é™é»˜æœŸ
```
# å·²çŸ¥ç»´æŠ¤çª—å£ï¼Œé™é»˜å‘Šè­¦
silence_alerts(
    start='2024-01-01 02:00',
    end='2024-01-01 04:00',
    reason='Database migration'
)
```

## OnCallæœ€ä½³å®è·µ

1. **è½®æ¢åˆ¶åº¦**: é¿å…åŒä¸€äººé•¿æœŸOnCall
2. **æ–‡æ¡£å…ˆè¡Œ**: Runbookå¿…é¡»å®Œå–„
3. **äº‹åå›é¡¾**: æ¯æ¬¡å‘Šè­¦åReview
4. **è‡ªåŠ¨åŒ–ä¼˜å…ˆ**: èƒ½è‡ªåŠ¨ä¿®å¤çš„ä¸è¦äººå·¥ä»‹å…¥
"""
]


async def main():
    """æ‰§è¡ŒçŸ¥è¯†åº“åˆå§‹åŒ–"""
    import asyncio
    from app.services.rag_service import RAGService
    
    print("ğŸš€ å¼€å§‹åˆå§‹åŒ–SREçŸ¥è¯†åº“...")
    
    # æ³¨æ„ï¼šè¿™é‡Œä¼ Noneæ˜¯å› ä¸ºåˆå§‹åŒ–ä¸éœ€è¦æ•°æ®åº“ä¼šè¯
    rag_service = RAGService(db=None)
    
    # åˆå§‹åŒ–çŸ¥è¯†åº“
    await rag_service.initialize_knowledge_base(SRE_KNOWLEDGE_DOCS)
    
    print("âœ… SREçŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆï¼")
    print(f"ğŸ“š å·²åŠ è½½ {len(SRE_KNOWLEDGE_DOCS)} ä¸ªæ ¸å¿ƒSREæ–‡æ¡£")
    print("\næ–‡æ¡£åˆ—è¡¨ï¼š")
    print("1. SREå››å¤§é»„é‡‘æŒ‡æ ‡")
    print("2. é”™è¯¯é¢„ç®—è¯¦è§£")
    print("3. ä»£ç å®¡æŸ¥SREæ£€æŸ¥æ¸…å•")
    print("4. SLO/SLI/SLAå®šä¹‰")
    print("5. å‘Šè­¦è®¾è®¡æœ€ä½³å®è·µ")


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
```

---

## Schemaå®šä¹‰ | Schema Definitions

**æ–‡ä»¶è·¯å¾„ | File Path**: `app/schemas/chat.py`

```python
from pydantic import BaseModel, Field
from typing import List, Dict, Optional

class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚Schema"""
    message: str = Field(..., description="ç”¨æˆ·æ¶ˆæ¯")
    session_id: str = Field(..., description="ä¼šè¯ID")
    visitor_id: str = Field(..., description="è®¿å®¢ID")
    context: Optional[List[Dict]] = Field(
        default=None,
        description="å¯¹è¯ä¸Šä¸‹æ–‡"
    )

class ChatResponse(BaseModel):
    """èŠå¤©å“åº”Schema"""
    success: bool
    data: Dict = Field(..., description="å“åº”æ•°æ®")
    
    class Config:
        schema_extra = {
            "example": {
                "success": True,
                "data": {
                    "message": "è¿™æ˜¯AIçš„å›ç­”",
                    "session_id": "session_123",
                    "question_type": "general_chat",
                    "timestamp": 1699999999999
                }
            }
        }
```

---

## ä¾èµ–æ›´æ–° | Dependencies Update

åœ¨ `requirements.txt` ä¸­æ·»åŠ RAGç›¸å…³ä¾èµ–ï¼š

```txt
# ... ç°æœ‰ä¾èµ– ...

# RAGç›¸å…³
chromadb==0.4.18
sentence-transformers==2.2.2  # å¦‚æœä½¿ç”¨æœ¬åœ°Embeddingï¼ˆå¯é€‰ï¼‰
```

---

## ä½¿ç”¨æµç¨‹ | Usage Flow

### 1. åˆå§‹åŒ–çŸ¥è¯†åº“ï¼ˆé¦–æ¬¡éƒ¨ç½²ï¼‰

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ
python scripts/init_knowledge_base.py
```

### 2. å¯åŠ¨åç«¯æœåŠ¡

```bash
uvicorn app.main:app --reload
```

### 3. å‰ç«¯è°ƒç”¨ç¤ºä¾‹

```javascript
// é€šç”¨é—®é¢˜ï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°LLMï¼‰
const response1 = await fetch('/api/v1/chat', {
  method: 'POST',
  body: JSON.stringify({
    message: "ä»€ä¹ˆæ˜¯SLOï¼Ÿ",
    session_id: "session_abc",
    visitor_id: "visitor_123"
  })
});

// æ·±åº¦é—®é¢˜ï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°RAGï¼‰
const response2 = await fetch('/api/v1/chat', {
  method: 'POST',
  body: JSON.stringify({
    message: "è¯·è¯¦ç»†è¯´æ˜SREå››å¤§é»„é‡‘æŒ‡æ ‡çš„æœ€ä½³å®è·µå’Œå…·ä½“å®ç°æ–¹æ¡ˆ",
    session_id: "session_abc",
    visitor_id: "visitor_123"
  })
});

// ä»£ç æ£€æŸ¥ï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°SREæ£€æŸ¥ï¼‰
const response3 = await fetch('/api/v1/chat', {
  method: 'POST',
  body: JSON.stringify({
    message: "è¯·æ£€æŸ¥è¿™æ®µä»£ç ï¼š\n```python\ndef get_users():\n    return db.query('SELECT * FROM users')\n```",
    session_id: "session_abc",
    visitor_id: "visitor_123"
  })
});
```

---

## Phase 1ä¸Phase 2+å¯¹æ¯” | Phase 1 vs Phase 2+ Comparison

| ç‰¹æ€§ | Phase 1 | Phase 2+ |
|------|---------|----------|
| **æ„å›¾åˆ†ç±»** | åŸºäºè§„åˆ™çš„å…³é”®è¯åŒ¹é… | BERTåˆ†ç±»æ¨¡å‹ |
| **å‘é‡æ•°æ®åº“** | æœ¬åœ°Chroma | äº‘ç«¯Pinecone/Weaviate |
| **çŸ¥è¯†åº“è§„æ¨¡** | 20-30ä¸ªæ ¸å¿ƒæ–‡æ¡£ | 100+æ–‡æ¡£ + åŠ¨æ€æ›´æ–° |
| **æ£€ç´¢ç­–ç•¥** | ç®€å•ç›¸ä¼¼åº¦æ£€ç´¢ | æ··åˆæ£€ç´¢ï¼ˆè¯­ä¹‰+å…³é”®è¯+é‡æ’åºï¼‰ |
| **æ¥æºå±•ç¤º** | ç®€å•æ–‡æœ¬å¼•ç”¨ | å¯ç‚¹å‡»çš„æ–‡æ¡£é“¾æ¥ |
| **çŸ¥è¯†åº“æ›´æ–°** | æ‰‹åŠ¨ç»´æŠ¤ | ç”¨æˆ·è‡ªå®šä¹‰ + è‡ªåŠ¨çˆ¬å– |
| **å¤šæ¨¡æ€** | çº¯æ–‡æœ¬ | æ”¯æŒå›¾ç‰‡ã€PDFã€ä»£ç ä»“åº“ |

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®® | Performance Optimization

### 1. Embeddingç¼“å­˜
```python
# ç¼“å­˜å¸¸è§é—®é¢˜çš„Embedding
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_question_embedding(question: str):
    return embeddings.embed_query(question)
```

### 2. æ‰¹é‡æ£€ç´¢
```python
# ä¸€æ¬¡æ£€ç´¢å¤šä¸ªç›¸å…³æ–‡æ¡£ï¼Œå‡å°‘è°ƒç”¨æ¬¡æ•°
retriever.get_relevant_documents(query, k=5)
```

### 3. å¼‚æ­¥å¤„ç†
```python
# ä½¿ç”¨å¼‚æ­¥æ–¹æ³•é¿å…é˜»å¡
await qa_chain.ainvoke({"query": message})
```

---

## ç›‘æ§æŒ‡æ ‡ | Monitoring Metrics

```python
# app/services/rag_service.py ä¸­æ·»åŠ ç›‘æ§
from prometheus_client import Counter, Histogram

# RAGè°ƒç”¨ç»Ÿè®¡
rag_requests_total = Counter('rag_requests_total', 'Total RAG requests')
rag_latency = Histogram('rag_request_duration_seconds', 'RAG request latency')
rag_relevance_score = Histogram('rag_relevance_score', 'Document relevance score')

@rag_latency.time()
async def get_rag_enhanced_response(self, message: str, context=None):
    rag_requests_total.inc()
    # ... ç°æœ‰é€»è¾‘
    
    # è®°å½•æ£€ç´¢ç›¸å…³æ€§
    for doc in sources:
        score = doc.metadata.get('score', 0)
        rag_relevance_score.observe(score)
```

---

## å¸¸è§é—®é¢˜ | FAQ

### Q1: ä¸ºä»€ä¹ˆPhase 1ä¸ç›´æ¥ä½¿ç”¨äº‘ç«¯å‘é‡æ•°æ®åº“ï¼Ÿ
**A**: æ§åˆ¶æˆæœ¬å’Œå¤æ‚åº¦ã€‚æœ¬åœ°Chromaè¶³å¤Ÿæ»¡è¶³MVPéœ€æ±‚ï¼Œä¸”ä¾¿äºå¼€å‘æµ‹è¯•ã€‚

### Q2: å¦‚ä½•åˆ¤æ–­RAGæ•ˆæœå¥½åï¼Ÿ
**A**: 
- ç›‘æ§æ£€ç´¢æ–‡æ¡£çš„ç›¸å…³æ€§åˆ†æ•°
- æ”¶é›†ç”¨æˆ·åé¦ˆï¼ˆæœ‰ç”¨/æ— ç”¨ï¼‰
- A/Bæµ‹è¯•å¯¹æ¯”çº¯LLMå’ŒRAGçš„å›ç­”è´¨é‡

### Q3: çŸ¥è¯†åº“å¦‚ä½•æŒç»­æ›´æ–°ï¼Ÿ
**A**:
- Phase 1: æ‰‹åŠ¨æ·»åŠ æ–‡æ¡£ï¼ˆ`scripts/add_document.py`ï¼‰
- Phase 2: æä¾›ç®¡ç†åå°ï¼Œæ”¯æŒåœ¨çº¿ä¸Šä¼ 
- Phase 3: è‡ªåŠ¨ä»å…¬å¸Wiki/ConfluenceåŒæ­¥

### Q4: å¦‚æœæ£€ç´¢ä¸åˆ°ç›¸å…³æ–‡æ¡£æ€ä¹ˆåŠï¼Ÿ
**A**: 
```python
if not sources or relevance_score < 0.5:
    # é™çº§åˆ°çº¯LLMå›ç­”
    return await llm_service.get_response(message)
```

---

## ä¸‹ä¸€æ­¥å¼€å‘ä»»åŠ¡ | Next Steps

**Phase 1:**
1. âœ… å®ç°IntentClassifier
2. âœ… å®ç°RAGService
3. âœ… æ›´æ–°chat.pyè·¯ç”±é€»è¾‘
4. âœ… ç¼–å†™çŸ¥è¯†åº“åˆå§‹åŒ–è„šæœ¬
5. âœ… æµ‹è¯•æ··åˆè·¯ç”±æ•ˆæœ

**Phase 2:**
1. è®­ç»ƒæ„å›¾åˆ†ç±»æ¨¡å‹
2. ä¼˜åŒ–æ£€ç´¢ç®—æ³•ï¼ˆHybrid Searchï¼‰
3. æ·»åŠ ç”¨æˆ·åé¦ˆæ”¶é›†
4. çŸ¥è¯†åº“ç®¡ç†åå°

**Phase 3:**
1. è¿ç§»åˆ°äº‘ç«¯å‘é‡æ•°æ®åº“
2. å¤šæ¨¡æ€RAGæ”¯æŒ
3. è‡ªå®šä¹‰çŸ¥è¯†åº“
4. RAGå¯ä¿¡åº¦è¯„åˆ†
